{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Representation Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "En esta notebook se implementa un modelo de representation learning a traves de un multilayer perceptron, la idea es que el modelo aprenda representaciones llenas de significado respecto las variables target. Probaremos por un lado la funcion de perdida del error cuadratico y por otro lado la funcion de perdida dada por el coeficiente de Spearman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pandas as pd \n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/raw_train_data.csv', index_col = 0)\n",
    "test = pd.read_csv('data/raw_test_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "continuous_features = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'MACD', 'RSI', 'BB_High', 'BB_Mid', 'BB_Low',\n",
    "    'ATR', 'NATR', 'Currency_Volume', 'Adj Close',\n",
    "    'BETA', 'TSF_7', 'TSF_14', 'TSF_28', 'Angle_7', 'Angle_14',\n",
    "    'Angle_28', 'Reg_7', 'Reg_14', 'Reg_28'\n",
    "]\n",
    "categorical_features = ['Month', 'Weekday', 'Ticker', 'Currency']\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer(transformers = [\n",
    "    ('continuous', StandardScaler(), continuous_features),\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore', sparse = False), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "    preprocessing_pipeline.fit_transform(train),\n",
    "    preprocessing_pipeline.transform(test),\n",
    "    train.Forward_Return_1m,\n",
    "    test.Forward_Return_1m\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'adam',\n",
    "    metrics = [\n",
    "        'RootMeanSquaredError',\n",
    "    ]\n",
    ")\n",
    "\n",
    "stopping = EarlyStopping(patience = 5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x0000020F1C6403A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0254 - root_mean_squared_error: 0.1593 - val_loss: 0.6730 - val_root_mean_squared_error: 0.8203\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f1c655608>"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "model.fit(X_train[:256], y_train[:256], epochs = 1, batch_size = 256, validation_data = (X_test[:1000], y_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.1871191283680306, pvalue=2.483074249516712e-09)"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "spearmanr(y_test[:1000], model.predict(X_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}