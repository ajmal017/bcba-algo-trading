{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return signals regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"data/all_tickers_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Ticker', 'MACD',\n",
       "       'RSI', 'BB_High', 'BB_Mid', 'BB_Low', 'ATR', 'NATR', 'Currency_Volume',\n",
       "       'Return_1m', 'Return_2m', 'Return_3m', 'Year', 'Month', 'Weekday',\n",
       "       'Forward_Return_1m', 'Forward_Return_2m', 'Forward_Return_3m'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['Open', 'High', 'Low', 'Close', 'Volume',\n",
    "                       'MACD', 'RSI', 'BB_High', 'BB_Mid', 'BB_Low',\n",
    "                       'ATR', 'NATR', 'Currency_Volume', 'Adj Close']\n",
    "categorical_features = ['Month', 'Weekday', 'Ticker', 'Currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class NoTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = ColumnTransformer(transformers = [\n",
    "    ('continuous', NoTransformer(), continuous_features),\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = continuous_features + categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiendo por grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('estimator', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_targets = [column for column in dataset.columns if 'Forward_' in column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid =[\n",
    "    {'estimator':[LinearRegression()]},\n",
    "    {\n",
    "        'estimator': [RandomForestRegressor()],\n",
    "        'estimator__max_depth': range(5, 16, 5),\n",
    "        'estimator__min_samples_split': [2, 5, 10, 15, 20]\n",
    "    },\n",
    "    {\n",
    "        'estimator': [LGBMRegressor(random_state = 42, silent = True)],\n",
    "        'estimator__n_estimators': range(10, 101, 10)\n",
    "    },\n",
    "    {\n",
    "        'estimator': [CatBoostRegressor(verbose = False)],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "source": [
    "Como queremos estimar varios targets en los cuales hay nulos en distintos rangos de tiempo, haremos cross-validation en cada caso."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['Currency'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7980cf475dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Forward_Return_1m'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Currency'] not in index\""
     ]
    }
   ],
   "source": [
    "target = 'Forward_Return_1m'\n",
    "\n",
    "model_data = dataset[features + [target]].dropna()\n",
    "X = model_data[features]\n",
    "y = model_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, shuffle = False, train_size = 0.8)\n",
    "cv = TimeSeriesSplit(n_splits = 2)\n",
    "model = GridSearchCV(pipeline, params_grid, cv = cv,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    return_train_score = True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.06444161908384105, 0.25385353864746707)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "r2 = r2_score(y_test, model.predict(X_test))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         mse      rmse ticker\n",
       "0   0.008389  0.091591  TECO2\n",
       "1   0.010790  0.103876   ALUA\n",
       "2   0.026015  0.161292   PAMP\n",
       "3   0.082880  0.287890   BHIP\n",
       "4   0.091155  0.301918   GGAL\n",
       "5   0.331363  0.575641   CEPU\n",
       "6   0.053514  0.231332    EDN\n",
       "7   0.022187  0.148954    BMA\n",
       "8   0.051138  0.226137   BBAR\n",
       "9   0.051927  0.227875   SUPV\n",
       "10  0.045981  0.214433    CVH\n",
       "11  0.047351  0.217602   LOMA"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>rmse</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.008389</td>\n      <td>0.091591</td>\n      <td>TECO2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010790</td>\n      <td>0.103876</td>\n      <td>ALUA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.026015</td>\n      <td>0.161292</td>\n      <td>PAMP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.082880</td>\n      <td>0.287890</td>\n      <td>BHIP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.091155</td>\n      <td>0.301918</td>\n      <td>GGAL</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.331363</td>\n      <td>0.575641</td>\n      <td>CEPU</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.053514</td>\n      <td>0.231332</td>\n      <td>EDN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.022187</td>\n      <td>0.148954</td>\n      <td>BMA</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.051138</td>\n      <td>0.226137</td>\n      <td>BBAR</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.051927</td>\n      <td>0.227875</td>\n      <td>SUPV</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.045981</td>\n      <td>0.214433</td>\n      <td>CVH</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.047351</td>\n      <td>0.217602</td>\n      <td>LOMA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "metrics = {\n",
    "    'mse': [],\n",
    "    'rmse': [],\n",
    "    'ticker': []\n",
    "}\n",
    "\n",
    "for ticker in X_test.Ticker.unique():\n",
    "    # Compute metrics by ticker\n",
    "    mask = X_test.Ticker == ticker\n",
    "    mse = mean_squared_error(y_test[mask], model.predict(X_test[mask]))\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Save in dict\n",
    "    metrics['ticker'].append(ticker)\n",
    "    metrics['mse'].append(mse)\n",
    "    metrics['rmse'].append(rmse)\n",
    "\n",
    "pd.DataFrame(metrics).sort_by(\"\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('models/trained_model_1m.pkl', 'wb')\n",
    "pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('data/test_data.pkl', 'wb')\n",
    "pickle.dump(X_train, file)\n",
    "file.close()"
   ]
  },
  {
   "source": [
    "## Modelo por representation learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn  import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_dnn(units_a = 32, units_b = 16):\n",
    "    n = len(features)\n",
    "    model = Sequential()\n",
    "    Dense(units_a, activation = 'relu', input_shape=(n,))\n",
    "    model.add(Dense(units_b, activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")   \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}